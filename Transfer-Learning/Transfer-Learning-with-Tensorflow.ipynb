{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "<h1><span style=\"color:purple\">Transfer Learning with TensorFlow</span> </h1>",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "![](https://images.unsplash.com/photo-1496483648148-47c686dc86a8?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&ixlib=rb-1.2.1&auto=format&fit=crop&w=1052&q=80)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "<h2><span style=\"color:Purple\">Introduction</span> </h2>\n\nClassical methods showed poor performance for image and text classification problems. The models which based on deep learning used to solve these problems. There are very much popular models which tested and open source that they are avaible for transfer learning.\nThe models such as ResNet are prebuilted and very complicated structures. TensorFlow Hub proposed a variety of ML models. You can use these model writting a single line of code.\nIn this tutorial, I am going to show how to use models pretrained in TensorFlow Hub. If you want to install Tensorflow Hub, you can use `pip install --upgrade tensorflow_hub` command. After installing, first of all, to use I am going to import this library `import tensorflow_hub as hub` command.\n\n<h2><span style=\"color:Purple\">Using the model in TensorFlow Hub</span> </h2>\n\nFor example, you can use a pretrained text embedding model in tensorFlow Hub such as `model = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim128/2\")`\nToken in this model based text embedding trained on English Google News 200B corpus. Text embedding is a multidimensional vector of numeric representation. Note that you can onlu load and use it to get a result with your own data. \n\nYou can choose the model in [TensorFlow Hub](https://tfhub.dev/) according to your the dataset. There are very much model for image, text, video, and audio datasets.\n\n<h2><span style=\"color:Purple\">Image Classification by Transfer Learning</span> </h2>\n\nIn this section, I am going to talk about how to analyze with transfer learning for classification problem. To show this, let me use flower photos dataset which provided by google. \nFirst of all, let's import libraries.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import tensorflow as tf\nimport tensorflow_hub as hub\nimport numpy as np\nimport matplotlib.pylab as plt\nimport pandas as pd",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-21T14:35:28.691759Z",
     "iopub.execute_input": "2021-08-21T14:35:28.692264Z",
     "iopub.status.idle": "2021-08-21T14:35:30.422399Z",
     "shell.execute_reply.started": "2021-08-21T14:35:28.692165Z",
     "shell.execute_reply": "2021-08-21T14:35:30.421514Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<h2><span style=\"color:Purple\">Loading the Dataset</span> </h2>",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "If you want you can directly load the dataset using get_file() method. `data_dir = tf.keras.utils.get_file('flower_photos','https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz', untar=True`. By default, you can see this dataset in .keras file such as `/root/.keras/datasets/flower_photos` on your machine. Now that I am going to create a variable for directory of dataset. ",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "data_dir = \"../input/flowers-recognition/flowers\"",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-21T14:35:33.851659Z",
     "iopub.execute_input": "2021-08-21T14:35:33.852023Z",
     "iopub.status.idle": "2021-08-21T14:35:33.856732Z",
     "shell.execute_reply.started": "2021-08-21T14:35:33.851989Z",
     "shell.execute_reply": "2021-08-21T14:35:33.855712Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<h2><span style=\"color:Purple\">Preprocessing the Dataset</span> </h2>",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "Now that I am going to define some hyperparameters such as pixel values and batch size.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "pixels =224\nBATCH_SIZE = 32\nIMAGE_SIZE = (pixels, pixels)\nNUM_CLASSES = 5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-21T14:35:37.561404Z",
     "iopub.execute_input": "2021-08-21T14:35:37.561742Z",
     "iopub.status.idle": "2021-08-21T14:35:37.567467Z",
     "shell.execute_reply.started": "2021-08-21T14:35:37.561711Z",
     "shell.execute_reply": "2021-08-21T14:35:37.565043Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "I am going to use ResNet model to analyze image classification. To use this model, you need to preprocess. Let me standardize image size to [223, 223, 3], and normalize pixel value tu a [0,1] range. First,let's create variable for hyperparameters.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "datagen_kwargs = dict(rescale = 1./255, validation_split = .20)\ndataflow_kwargs = dict(target_size = IMAGE_SIZE, batch_size = BATCH_SIZE, interpolation = \"bilinear\")",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-21T14:35:41.193151Z",
     "iopub.execute_input": "2021-08-21T14:35:41.193511Z",
     "iopub.status.idle": "2021-08-21T14:35:41.198520Z",
     "shell.execute_reply.started": "2021-08-21T14:35:41.193478Z",
     "shell.execute_reply": "2021-08-21T14:35:41.197157Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "I am going to split dataset into train and validation.  While validation dataset uses for cross validation, the other dataset uses for training model. ",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Generating batches of tensor image-data and creating validation dataset.\nvalid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)\nvalid_generator = valid_datagen.flow_from_directory( data_dir, subset=\"validation\", shuffle=False, **dataflow_kwargs)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-21T14:35:44.172634Z",
     "iopub.execute_input": "2021-08-21T14:35:44.172994Z",
     "iopub.status.idle": "2021-08-21T14:35:46.186342Z",
     "shell.execute_reply.started": "2021-08-21T14:35:44.172958Z",
     "shell.execute_reply": "2021-08-21T14:35:46.185439Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": "Found 860 images belonging to 5 classes.\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "Now, do the same for the training data generator. ",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "train_datagen = valid_datagen\ntrain_generator = train_datagen.flow_from_directory( data_dir, subset=\"training\", shuffle=True, **dataflow_kwargs)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-21T14:35:49.362076Z",
     "iopub.execute_input": "2021-08-21T14:35:49.362397Z",
     "iopub.status.idle": "2021-08-21T14:35:49.578153Z",
     "shell.execute_reply.started": "2021-08-21T14:35:49.362368Z",
     "shell.execute_reply": "2021-08-21T14:35:49.577265Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": "Found 3457 images belonging to 5 classes.\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "I am going to define class name. To do this, let me map flower class names.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "labels_idx = (train_generator.class_indices)\nidx_labels = dict((v,k) for k,v in labels_idx.items())\n#Let's take a look how to map classes.\nidx_labels",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-21T14:35:52.081377Z",
     "iopub.execute_input": "2021-08-21T14:35:52.081710Z",
     "iopub.status.idle": "2021-08-21T14:35:52.090420Z",
     "shell.execute_reply.started": "2021-08-21T14:35:52.081678Z",
     "shell.execute_reply": "2021-08-21T14:35:52.089376Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": [
    {
     "execution_count": 7,
     "output_type": "execute_result",
     "data": {
      "text/plain": "{0: 'daisy', 1: 'dandelion', 2: 'rose', 3: 'sunflower', 4: 'tulip'}"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "<h2><span style=\"color:Purple\">Building the Model</span> </h2>",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "Datasets are ready to build the model. I am going to train using pretrain model. ",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "model = tf.keras.Sequential([\n    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v1_101/feature_vector/4\", trainable=False),\n    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax', name = 'flower_class') \n])\n\nmodel.build([None, 224, 224, 3])",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-21T14:35:55.142535Z",
     "iopub.execute_input": "2021-08-21T14:35:55.142869Z",
     "iopub.status.idle": "2021-08-21T14:36:03.807464Z",
     "shell.execute_reply.started": "2021-08-21T14:35:55.142837Z",
     "shell.execute_reply": "2021-08-21T14:36:03.806454Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<h2><span style=\"color:Purple\">Compiling the Model</span> </h2>",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "After the model is built I am going to compile the model. To do this, let me specify the loss funciton and pick an optimizer.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "model.compile(\n    optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0.9),\n    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n    metrics=['accuracy'])",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-21T14:36:09.493435Z",
     "iopub.execute_input": "2021-08-21T14:36:09.493755Z",
     "iopub.status.idle": "2021-08-21T14:36:09.513660Z",
     "shell.execute_reply.started": "2021-08-21T14:36:09.493725Z",
     "shell.execute_reply": "2021-08-21T14:36:09.510646Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Let's take a look summary of model.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "model.summary()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-21T14:36:11.891503Z",
     "iopub.execute_input": "2021-08-21T14:36:11.891850Z",
     "iopub.status.idle": "2021-08-21T14:36:11.913030Z",
     "shell.execute_reply.started": "2021-08-21T14:36:11.891819Z",
     "shell.execute_reply": "2021-08-21T14:36:11.911897Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nkeras_layer (KerasLayer)     (None, 2048)              42605504  \n_________________________________________________________________\nflower_class (Dense)         (None, 5)                 10245     \n=================================================================\nTotal params: 42,615,749\nTrainable params: 10,245\nNon-trainable params: 42,605,504\n_________________________________________________________________\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "<h2><span style=\"color:Purple\">Training the Model</span> </h2>",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "Let's traing the model. First, let me determine the number of batches for training and cross-validation data.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "steps_per_epoch = train_generator.samples // train_generator.batch_size\nvalidation_steps = valid_generator.samples // valid_generator.batch_size",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-21T14:36:15.178621Z",
     "iopub.execute_input": "2021-08-21T14:36:15.179008Z",
     "iopub.status.idle": "2021-08-21T14:36:15.183115Z",
     "shell.execute_reply.started": "2021-08-21T14:36:15.178971Z",
     "shell.execute_reply": "2021-08-21T14:36:15.182053Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Now that I am going to fit model.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "model.fit(\n    train_generator,\n    epochs=5, \n    steps_per_epoch=steps_per_epoch,\n    validation_data=valid_generator,\n    validation_steps=validation_steps)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-21T14:36:18.191792Z",
     "iopub.execute_input": "2021-08-21T14:36:18.192137Z",
     "iopub.status.idle": "2021-08-21T14:38:42.279732Z",
     "shell.execute_reply.started": "2021-08-21T14:36:18.192106Z",
     "shell.execute_reply": "2021-08-21T14:38:42.278641Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": "Epoch 1/5\n108/108 [==============================] - 55s 387ms/step - loss: 1.1933 - accuracy: 0.7062 - val_loss: 0.8538 - val_accuracy: 0.8281\nEpoch 2/5\n108/108 [==============================] - 22s 207ms/step - loss: 0.7529 - accuracy: 0.8702 - val_loss: 0.8119 - val_accuracy: 0.8401\nEpoch 3/5\n108/108 [==============================] - 22s 204ms/step - loss: 0.6159 - accuracy: 0.9276 - val_loss: 0.7251 - val_accuracy: 0.8762\nEpoch 4/5\n108/108 [==============================] - 22s 205ms/step - loss: 0.5700 - accuracy: 0.9480 - val_loss: 0.8214 - val_accuracy: 0.8329\nEpoch 5/5\n108/108 [==============================] - 22s 205ms/step - loss: 0.5962 - accuracy: 0.9396 - val_loss: 0.7267 - val_accuracy: 0.8642\n",
     "output_type": "stream"
    },
    {
     "execution_count": 12,
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f38b55cbe10>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "<h2><span style=\"color:Purple\">Predicting the Data</span> </h2>",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "You can use predict() method to score these validation images. Let's see predictions for first batch.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "sample_test_images, ground_truth_labels = next(valid_generator)\nprediction = model.predict(valid_generator)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-21T14:40:05.531671Z",
     "iopub.execute_input": "2021-08-21T14:40:05.532061Z",
     "iopub.status.idle": "2021-08-21T14:40:11.888449Z",
     "shell.execute_reply.started": "2021-08-21T14:40:05.532020Z",
     "shell.execute_reply": "2021-08-21T14:40:11.887536Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "len(prediction)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-21T14:40:15.121839Z",
     "iopub.execute_input": "2021-08-21T14:40:15.122215Z",
     "iopub.status.idle": "2021-08-21T14:40:15.130049Z",
     "shell.execute_reply.started": "2021-08-21T14:40:15.122181Z",
     "shell.execute_reply": "2021-08-21T14:40:15.127061Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": [
    {
     "execution_count": 14,
     "output_type": "execute_result",
     "data": {
      "text/plain": "860"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "731 images and 5 corresponding classes in the cross-validation data print out on the screen. The highest probability in each row represents the prediction. I am going to find position where the highest probability occurs for each row.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "predicted_idx = tf.math.argmax(prediction, axis = -1)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-21T14:40:18.029165Z",
     "iopub.execute_input": "2021-08-21T14:40:18.029524Z",
     "iopub.status.idle": "2021-08-21T14:40:18.035436Z",
     "shell.execute_reply.started": "2021-08-21T14:40:18.029494Z",
     "shell.execute_reply": "2021-08-21T14:40:18.034498Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Let me display the result using print command.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "print (predicted_idx)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-21T14:40:20.779284Z",
     "iopub.execute_input": "2021-08-21T14:40:20.779616Z",
     "iopub.status.idle": "2021-08-21T14:40:20.789360Z",
     "shell.execute_reply.started": "2021-08-21T14:40:20.779582Z",
     "shell.execute_reply": "2021-08-21T14:40:20.788447Z"
    },
    "trusted": true
   },
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "text": "tf.Tensor(\n[0 0 0 0 0 0 3 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 1 0 3 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 1 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 4 1 1 3\n 1 3 3 1 1 1 1 0 3 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 3 1 1 1 1 1 3 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n 1 1 1 1 0 1 0 1 1 1 1 3 1 1 1 0 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 0 1 3 1 0 1 1 1 3 1 1 3 1 1 1 1 1 1 2 2 2 2 2 4 2 3\n 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 4 2 2 2 4 2 2 2 2 2 2 2 4 2 2 2 2 2 2\n 2 2 2 2 2 1 4 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 4 2 2 2 2 2 2 2 2 2 2 2 2 0 3 2 2\n 2 2 2 2 2 2 2 2 2 3 2 3 2 2 2 2 2 2 2 2 4 2 3 2 3 2 2 3 2 4 2 1 2 2 2 3 1\n 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 0 3 3 1 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3\n 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 3 3 3 3 3 3 3 3 3 1 3 3 3 3 3 3\n 3 3 3 3 3 3 3 3 3 3 3 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 2 3 3 1 3 1 2 3 3 3 3 3 3 3 3 4 4\n 4 4 4 4 2 4 4 4 2 0 4 4 2 4 4 4 4 2 2 4 4 4 4 4 0 4 4 4 4 4 4 4 4 4 4 4 4\n 1 4 3 4 4 4 2 4 4 4 2 4 4 0 4 4 4 4 1 4 3 4 4 4 4 1 1 3 4 4 4 4 4 4 4 4 2\n 4 4 4 4 4 4 1 4 4 4 4 4 4 4 2 4 4 4 4 2 4 4 4 2 4 3 4 4 4 4 4 4 4 4 1 4 4\n 4 4 4 4 3 3 4 4 3 2 4 1 4 4 4 2 4 4 4 4 0 4 2 4 3 4 4 4 4 4 2 4 4 4 4 4 2\n 4 4 4 4 2 4 4 4 4 4 4 4 4 4 2 1 4 4 4 4 1 4 4 4 4 2 4 4 4 2 4 4 4 4 4 4 4\n 4 4 4 4 4 4 1 4 4], shape=(860,), dtype=int64)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "<h2><span style=\"color:Purple\">Evaluating the Model</span> </h2>",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "To evaluate the model, I am going to use confusion matrix, which compare model output with ground truth. To do this let me convert classes into Pandas Series structure and create variable, which include predictions.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "y_actual = pd.Series(valid_generator.classes)\ny_predicted = pd.Series(predicted_idx)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-21T14:40:23.769352Z",
     "iopub.execute_input": "2021-08-21T14:40:23.769682Z",
     "iopub.status.idle": "2021-08-21T14:40:23.777647Z",
     "shell.execute_reply.started": "2021-08-21T14:40:23.769650Z",
     "shell.execute_reply": "2021-08-21T14:40:23.776642Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Then I am going to produce the matrix.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "pd.crosstab(y_actual, y_predicted, rownames = ['Actual'], colnames=['Predicted'], margins=True)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-21T14:40:28.557700Z",
     "iopub.execute_input": "2021-08-21T14:40:28.558065Z",
     "iopub.status.idle": "2021-08-21T14:40:28.641821Z",
     "shell.execute_reply.started": "2021-08-21T14:40:28.558028Z",
     "shell.execute_reply": "2021-08-21T14:40:28.640881Z"
    },
    "trusted": true
   },
   "execution_count": 18,
   "outputs": [
    {
     "execution_count": 18,
     "output_type": "execute_result",
     "data": {
      "text/plain": "Predicted    0    1    2    3    4  All\nActual                                 \n0          140    5    1    5    1  152\n1            9  184    1   15    1  210\n2            1    5  132    9    9  156\n3            1    6    4  133    2  146\n4            4   10   20    8  154  196\nAll        155  210  158  170  167  860",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Predicted</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>All</th>\n    </tr>\n    <tr>\n      <th>Actual</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>140</td>\n      <td>5</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>152</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9</td>\n      <td>184</td>\n      <td>1</td>\n      <td>15</td>\n      <td>1</td>\n      <td>210</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>5</td>\n      <td>132</td>\n      <td>9</td>\n      <td>9</td>\n      <td>156</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>6</td>\n      <td>4</td>\n      <td>133</td>\n      <td>2</td>\n      <td>146</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>10</td>\n      <td>20</td>\n      <td>8</td>\n      <td>154</td>\n      <td>196</td>\n    </tr>\n    <tr>\n      <th>All</th>\n      <td>155</td>\n      <td>210</td>\n      <td>158</td>\n      <td>170</td>\n      <td>167</td>\n      <td>860</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "Each row represents predicted value and each column display actual values. \nNow that let's take a look statistical report using sklearn library.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "To see metrics my model, I going to create variables.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "predicted_results = y_predicted\ntruth = y_actual",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-21T14:40:31.499623Z",
     "iopub.execute_input": "2021-08-21T14:40:31.499972Z",
     "iopub.status.idle": "2021-08-21T14:40:31.505159Z",
     "shell.execute_reply.started": "2021-08-21T14:40:31.499921Z",
     "shell.execute_reply": "2021-08-21T14:40:31.504206Z"
    },
    "trusted": true
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "To evaluate the model, metrics are used. I am going to use sklearn library to see metrics. ",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from sklearn.metrics import classification_report\nreport = classification_report(truth, predicted_results)\nprint(report)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-21T14:40:34.119439Z",
     "iopub.execute_input": "2021-08-21T14:40:34.119780Z",
     "iopub.status.idle": "2021-08-21T14:40:34.627668Z",
     "shell.execute_reply.started": "2021-08-21T14:40:34.119749Z",
     "shell.execute_reply": "2021-08-21T14:40:34.626685Z"
    },
    "trusted": true
   },
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "text": "              precision    recall  f1-score   support\n\n           0       0.90      0.92      0.91       152\n           1       0.88      0.88      0.88       210\n           2       0.84      0.85      0.84       156\n           3       0.78      0.91      0.84       146\n           4       0.92      0.79      0.85       196\n\n    accuracy                           0.86       860\n   macro avg       0.86      0.87      0.86       860\nweighted avg       0.87      0.86      0.86       860\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "This results say that the model has good performance for classification problem. \n\n<h2><span style=\"color:Purple\">Using the tf.keras.applications Module</span> </h2>\n\nKeras is an API, which is a high level library. This module became a part of  the TensorFlow ecosystem in 2019. You can use Keras to fine tune your models. tf.keras.applications lets you determine which layers to retrain and which layers to untouched. Let's create a new base model using tf.keras.applications. ",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "base_model = tf.keras.applications.ResNet101V2(\n    input_shape = (224, 224, 3), \n    include_top = False, \n    weights = 'imagenet')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-21T14:40:37.600458Z",
     "iopub.execute_input": "2021-08-21T14:40:37.600792Z",
     "iopub.status.idle": "2021-08-21T14:40:41.355188Z",
     "shell.execute_reply.started": "2021-08-21T14:40:37.600759Z",
     "shell.execute_reply": "2021-08-21T14:40:41.354197Z"
    },
    "trusted": true
   },
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "text": "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n171319296/171317808 [==============================] - 1s 0us/step\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "First, I specified input shape and then I set include_top to False so I can add my own Dense layer for the classification output. \nNow that I am going to build Sequential model based on base model and add GlobalAveragePooling2D layer. ",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "model2 = tf.keras.Sequential([\n  base_model,\n  tf.keras.layers.GlobalAveragePooling2D(),\n  tf.keras.layers.Dense(NUM_CLASSES, activation = 'softmax', name = 'flower_class')\n])",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-21T14:40:44.388436Z",
     "iopub.execute_input": "2021-08-21T14:40:44.388791Z",
     "iopub.status.idle": "2021-08-21T14:40:45.105602Z",
     "shell.execute_reply.started": "2021-08-21T14:40:44.388759Z",
     "shell.execute_reply": "2021-08-21T14:40:45.104760Z"
    },
    "trusted": true
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Now that let me compile and fit the model.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "model2.compile(\n  optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0.9),\n  loss=tf.keras.losses.CategoricalCrossentropy(\n  from_logits=True, label_smoothing=0.1),\n  metrics=['accuracy']\n)\nmodel2.fit(\n    train_generator,\n    epochs=5, steps_per_epoch=steps_per_epoch,\n    validation_data=valid_generator,\n    validation_steps=validation_steps)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-21T14:40:48.969703Z",
     "iopub.execute_input": "2021-08-21T14:40:48.970108Z",
     "iopub.status.idle": "2021-08-21T14:43:53.070724Z",
     "shell.execute_reply.started": "2021-08-21T14:40:48.970070Z",
     "shell.execute_reply": "2021-08-21T14:43:53.069901Z"
    },
    "trusted": true
   },
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "text": "Epoch 1/5\n108/108 [==============================] - 46s 339ms/step - loss: 1.0235 - accuracy: 0.6899 - val_loss: 0.9128 - val_accuracy: 0.7800\nEpoch 2/5\n108/108 [==============================] - 34s 316ms/step - loss: 0.5290 - accuracy: 0.9554 - val_loss: 0.6687 - val_accuracy: 0.8858\nEpoch 3/5\n108/108 [==============================] - 34s 317ms/step - loss: 0.4791 - accuracy: 0.9792 - val_loss: 0.6403 - val_accuracy: 0.9002\nEpoch 4/5\n108/108 [==============================] - 34s 318ms/step - loss: 0.4522 - accuracy: 0.9886 - val_loss: 0.6220 - val_accuracy: 0.9038\nEpoch 5/5\n108/108 [==============================] - 34s 318ms/step - loss: 0.4284 - accuracy: 0.9953 - val_loss: 0.6029 - val_accuracy: 0.9014\n",
     "output_type": "stream"
    },
    {
     "execution_count": 23,
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f347d358390>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "<h2><span style=\"color:Purple\">Fine-Tuning Model</span> </h2>\nYou can fine tune your model using tf.keras.applications. Let's take a look number of layer in base model. ",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "print(\"Number of layers in the base model: \", len(base_model.layers))\nbase_model.trainable = True",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-21T14:43:57.469824Z",
     "iopub.execute_input": "2021-08-21T14:43:57.470202Z",
     "iopub.status.idle": "2021-08-21T14:43:57.488588Z",
     "shell.execute_reply.started": "2021-08-21T14:43:57.470170Z",
     "shell.execute_reply": "2021-08-21T14:43:57.487071Z"
    },
    "trusted": true
   },
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "text": "Number of layers in the base model:  377\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "As you can see, there are 377 layers. I am going to take 370 layers as the starting layer for fine tuning. I want these layers not to be trained.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Freezing all the layers before the 'fine_tune_at' layer\nfine_tune_at = 300\nfor layer in base_model.layers[: fine_tune_at]:\n    layer.trainable = False",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-21T14:44:00.229437Z",
     "iopub.execute_input": "2021-08-21T14:44:00.229765Z",
     "iopub.status.idle": "2021-08-21T14:44:00.243224Z",
     "shell.execute_reply.started": "2021-08-21T14:44:00.229734Z",
     "shell.execute_reply": "2021-08-21T14:44:00.241967Z"
    },
    "trusted": true
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Now that I am going to build the model again. ",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "model3 = tf.keras.Sequential([\n    base_model,\n    tf.keras.layers.GlobalAveragePooling2D(), \n    tf.keras.layers.Dense(NUM_CLASSES, activation = 'softmax', name = 'flower_class')\n])",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-21T14:44:02.850685Z",
     "iopub.execute_input": "2021-08-21T14:44:02.851035Z",
     "iopub.status.idle": "2021-08-21T14:44:03.520244Z",
     "shell.execute_reply.started": "2021-08-21T14:44:02.851002Z",
     "shell.execute_reply": "2021-08-21T14:44:03.519318Z"
    },
    "trusted": true
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Let me compile the model.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "model3.compile(\n    optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0.9),\n    loss=tf.keras.losses.CategoricalCrossentropy(\n        from_logits=True, label_smoothing=0.1),\n    metrics=['accuracy']\n)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-21T14:44:07.268749Z",
     "iopub.execute_input": "2021-08-21T14:44:07.269103Z",
     "iopub.status.idle": "2021-08-21T14:44:07.288095Z",
     "shell.execute_reply.started": "2021-08-21T14:44:07.269072Z",
     "shell.execute_reply": "2021-08-21T14:44:07.287028Z"
    },
    "trusted": true
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Let's take a look summary of the model3.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "model3.summary()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-21T14:44:10.439592Z",
     "iopub.execute_input": "2021-08-21T14:44:10.439955Z",
     "iopub.status.idle": "2021-08-21T14:44:10.471037Z",
     "shell.execute_reply.started": "2021-08-21T14:44:10.439904Z",
     "shell.execute_reply": "2021-08-21T14:44:10.470164Z"
    },
    "trusted": true
   },
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "text": "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nresnet101v2 (Functional)     (None, 7, 7, 2048)        42626560  \n_________________________________________________________________\nglobal_average_pooling2d_1 ( (None, 2048)              0         \n_________________________________________________________________\nflower_class (Dense)         (None, 5)                 10245     \n=================================================================\nTotal params: 42,636,805\nTrainable params: 19,189,253\nNon-trainable params: 23,447,552\n_________________________________________________________________\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "Let me train the model.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "fine_tune_epochs = 2\nsteps_per_epoch = train_generator.samples // train_generator.batch_size\nvalidation_steps = valid_generator.samples // valid_generator.batch_size\nmodel3.fit(\n    train_generator,\n    epochs=fine_tune_epochs, \n    steps_per_epoch=steps_per_epoch,\n    validation_data=valid_generator,\n    validation_steps=validation_steps)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-21T14:44:14.579666Z",
     "iopub.execute_input": "2021-08-21T14:44:14.580019Z",
     "iopub.status.idle": "2021-08-21T14:45:11.755135Z",
     "shell.execute_reply.started": "2021-08-21T14:44:14.579983Z",
     "shell.execute_reply": "2021-08-21T14:45:11.754260Z"
    },
    "trusted": true
   },
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "text": "Epoch 1/2\n108/108 [==============================] - 33s 253ms/step - loss: 0.7754 - accuracy: 0.8275 - val_loss: 0.6068 - val_accuracy: 0.9087\nEpoch 2/2\n108/108 [==============================] - 24s 224ms/step - loss: 0.4337 - accuracy: 0.9963 - val_loss: 0.5915 - val_accuracy: 0.9147\n",
     "output_type": "stream"
    },
    {
     "execution_count": 29,
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f34744c5d10>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "My model has 0.996 accuracy value. This is a good value. That is all. In this tutorial, I showed how to use the pretrained model. To do pretrained model, there are two convenient ways: TensorFlow Hub and the tf.keras.applications module. You can easily train the your model according to your analysis using the pretrained models.",
   "metadata": {}
  }
 ]
}
