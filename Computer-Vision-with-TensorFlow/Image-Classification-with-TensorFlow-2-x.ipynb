{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# <span style=\"color:OrangeRed\">Image Classification with TensorFlow 2.x</span>\nIn this notebook, I will explain classifying images using deep neural networks with TensoFlow.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "![Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist/blob/master/doc/img/fashion-mnist-sprite.png?raw=true)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Loading Fashion MNIST dataset\nimport tensorflow as tf\nfashion_mnist = tf.keras.datasets.fashion_mnist\n(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Let's look at the shape and data type of the training and test set.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "X_train.shape, X_test.shape",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## <span style=\"color:OrangeRed\">Data Preprocessing</span>\nLet's assign the names of fashion items corresponding to these numbers to a variable.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class_names = [\"T-shirt / top\", \"Trouser\", \"Pullover\", \"Dress\",\n        \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Let's use the matplotlib library to see the second image.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import matplotlib.pyplot as plt\nplt.figure()\nplt.imshow (X_train[1])\nplt.colorbar()\nplt.grid(False)\nplt.show()",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Let's scale the inputs to increase the training speed and performance of the model.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "X_train = X_train / 255.0\nX_test = X_test / 255.0",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## <span style=\"color:OrangeRed\">Building the Model</span>\nLet's start building the model.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "model = tf.keras.Sequential ([\n   tf.keras.layers.Flatten (input_shape = (28, 28), name = \"Input\"),\n   tf.keras.layers.Dense (128, activation = 'relu', name = \"Hidden\"),\n   tf.keras.layers.Dense (10, name = \"Output\")\n])",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "\nThe model's summary() method shows all layers of the model with the names of the layers.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "model.summary()",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "You can easily get a model's list of layers, to fetch a layer by its index, or you can fetch it by name:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "model.layers",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "hidden = model.layers[1]\nprint(hidden.name)",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "All parameters of a layer can be accessed with the get_weights () and set_weights () methods. Let's look at both the weights and the bias of the first layer.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "weights, biases = hidden.get_weights ()\nprint(weights)",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "print(biases)",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "weights.shape, biases.shape",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## <span style=\"color:OrangeRed\">Compiling the Model</span>\nThe Loss function measures how accurately the model predicts during training. We want to minimize this function in order to direct the model in the right direction. The optimizer updates the model based on the loss function and the data it sees. The Metrics argument is used to monitor training and testing steps.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(\n                         from_logits = True),\n              optimizer = 'adam',\n              metrics = ['accuracy'])",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## <span style=\"color:OrangeRed\">Training the Model</span>\nNow we can train the model by calling the fit () method.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "history = model.fit (X_train, y_train, epochs = 10, validation_split = 0.1)",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "The fit () method returns a History object containing training parameters. history.history is in the form of a dictionary. This dictionary includes metric and loss measured after each epoch in training and validation sets. If you convert this dictionary structure to a Pandas DataFrame structure and use the plot () method, you can plot the training curve.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import pandas as pd\npd.DataFrame (history.history).plot (figsize = (8, 5))\nplt.grid(True)\nplt.show()",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## <span style=\"color:OrangeRed\">Evaluating the Model</span> \nLet's call evaluate () method and evaluate the model by using test set.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "test_loss, test_acc = model.evaluate (X_test, y_test, verbose = 2)\nprint ('\\ nTest accuracy:', test_acc)",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## <span style=\"color:OrangeRed\">Making a Prediction</span> \nYou can convert logits into possibilities by adding a softmax layer for easier interpretation.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "probability_model = tf.keras.Sequential ([model, tf.keras.layers.Softmax()])",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Let's estimate the test data based on this model.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "predictions = probability_model.predict(X_test)",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "So the model predicted the label of each picture on the test set. Let's take a first predict.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "predictions[0]",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Note that 10 possibilities corresponding to each fashion item were returned. You can see the label with the highest probability using the argmax method in NumPy.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\nnp.argmax(predictions[0])",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "The model predicted the first image as the ankle boot. Let's take a look at the actual label of the first image.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "y_test[0]",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "As you can see, the model made the correct prediction.\n\n----",
   "metadata": {}
  }
 ]
}
