{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyO9Zzm5eyUjAAYeJXfTbxU+",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# How to the TextVectorization Layer in TensorFLow"
   ],
   "metadata": {
    "id": "BtCRHk7d9pMK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization"
   ],
   "metadata": {
    "id": "5pyat2_2uojp"
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Instanting\n",
    "text_vectorization = TextVectorization() # TextVectorization removes text lowercase transliteration and punctuation. And it splits the text into words. "
   ],
   "metadata": {
    "id": "L3RsgOluyiyU"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data = [\n",
    "    \"Bugün hava çok güzel\", # eng: Today the weather is very nice\n",
    "    \"Ali, Efe ve baki çay içecek\", # eng: Ali, Efe and Baki will drink tea\n",
    "    \"Selam söyle\" # eng: Say hello\n",
    "]"
   ],
   "metadata": {
    "id": "iY8S5onGytHD"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Creating the vocabulary with the adapt method.\n",
    "text_vectorization.adapt(data)"
   ],
   "metadata": {
    "id": "4ngXk1j4zCbb"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Let's take a look at the vocabulary.\n",
    "text_vectorization.get_vocabulary() # The first two words are reserved for padding and out-of-vocabulary tokens. Out-of vocabulary means that the word is not in the vocabulary. Padding is used to make the input data the same size."
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05I_y-XVzKDl",
    "outputId": "3a62d4aa-b4f2-4d50-cced-b6f61fb1b09e"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'çok',\n",
       " 'çay',\n",
       " 've',\n",
       " 'söyle',\n",
       " 'selam',\n",
       " 'içecek',\n",
       " 'hava',\n",
       " 'güzel',\n",
       " 'efe',\n",
       " 'ece',\n",
       " 'bugün',\n",
       " 'ali']"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Data preprocessing with the layer\n",
    "vectorized_text = text_vectorization(data)  \n",
    "vectorized_text # The first two words are reserved for padding and out-of-vocabulary tokens. Out-of vocabulary means that the word is not in the vocabulary. Padding is used to make the input data the same size."
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OEdicTg-zTQj",
    "outputId": "5a7a8e1e-31ca-4e50-fbd5-b996193eb0a3"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 6), dtype=int64, numpy=\n",
       "array([[12,  8,  2,  9,  0,  0],\n",
       "       [13, 10,  4, 11,  3,  7],\n",
       "       [ 6,  5,  0,  0,  0,  0]])>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Using the custom functions TextVectorization"
   ],
   "metadata": {
    "id": "uDU2o1dl7jI1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import re\n",
    "import string"
   ],
   "metadata": {
    "id": "BGgSQArYzpvE"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def standardization_fn(string_tensor): # The standardization function removes punctuation and lowercases the text.\n",
    "  lowercase = tf.strings.lower(string_tensor)\n",
    "  return tf.strings.regex_replace(\n",
    "      lowercase, f\"[{re.escape(string.punctuation)}]\", \"\" # The re.escape() function returns a string with all non-alphanumerics backslashed; this is useful if you want to match an arbitrary literal string that may have regular expression metacharacters in it.\n",
    "  )"
   ],
   "metadata": {
    "id": "aIx40gV406yD"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def split_fn(string_tensor): # The split function splits the string into words.\n",
    "  return tf.strings.split(string_tensor)"
   ],
   "metadata": {
    "id": "4T19MwA42RSq"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "text_vectorization = TextVectorization(\n",
    "    standardize=standardization_fn,\n",
    "    split = split_fn\n",
    ")"
   ],
   "metadata": {
    "id": "LwuWFbHC2qKT"
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "text_vectorization.adapt(data)"
   ],
   "metadata": {
    "id": "GUlD9_573H9K"
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Testing our layer with a text\n",
    "text = \"bugün ece çok güzel\" # eng: today ece is very nice\n",
    "text_vectorization(text)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AXmh5k_s3P_s",
    "outputId": "ba39b903-e28b-412e-fa10-53112277cee4"
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([12, 11,  2,  9])>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Using TextVectorization in a model"
   ],
   "metadata": {
    "id": "YbTuG4QN8jtx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Creating a Dataset object\n",
    "text_dataset = tf.data.Dataset.from_tensor_slices([\n",
    "    \"kedi\", \"aslan\", \"yunus\" # eng: cat, lion, dolphin\n",
    "])"
   ],
   "metadata": {
    "id": "BPDzXpJW3wIq"
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Creating the TextVectorization layer. The output_sequence_length parameter is used to make the output data the same size.\n",
    "vectorize_layer = tf.keras.layers.TextVectorization( # The TextVectorization layer removes text lowercase transliteration and punctuation. And it splits the text into words.\n",
    "    max_tokens=5000, # The maximum number of words in the vocabulary\n",
    "    output_sequence_length=4 # The output data size. Array size. Padding is used to make the input data the same size.\n",
    ")"
   ],
   "metadata": {
    "id": "PB6sAoHf4Ydq"
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Creating the vocabulary\n",
    "vectorize_layer.adapt(text_dataset.batch(64))"
   ],
   "metadata": {
    "id": "5mqlU58R40P-"
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "vectorize_layer.get_vocabulary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2sIxlLm-5RYq",
    "outputId": "1158826e-0f5c-427a-d143-25d2a7b7a895"
   },
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['', '[UNK]', 'yunus', 'kedi', 'aslan']"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Building the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=(1,), dtype=tf.string), # The input shape is the shape of the input data. The input data is a string.\n",
    "    vectorize_layer\n",
    "])"
   ],
   "metadata": {
    "id": "nAMORijK5WTC"
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Getting a data for testing\n",
    "input_data=[[\"kedi kartal aslan\"], [\"fok yunus\"]]"
   ],
   "metadata": {
    "id": "ZtqlDmjY5vx7"
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.predict(input_data)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mISY78tN6AfL",
    "outputId": "711c2821-cc29-42c0-e991-9753fde97f92"
   },
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/1 [==============================] - 0s 310ms/step\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[3, 1, 4, 0],\n",
       "       [1, 2, 0, 0]])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "array([[3 (kedi), 1 (kartal), 4 (aslan), 0 (padding)],\n",
    "       [1, 2, 0, 0]])\n",
    "Padding (0) is used to make the input data the same size. 1 means out of vocabulary "
   ]
  }
 ]
}
